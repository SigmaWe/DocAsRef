{
  "('pearsonr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.4434992114,
  "('pearsonr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.2634742166,
  "('pearsonr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.380797658,
  "('pearsonr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.4435065481,
  "('pearsonr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.2652205378,
  "('pearsonr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.382082738,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.1928473391,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.10898753,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.1902080009,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.0900346454,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.0504193139,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.0792121088,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.165622161,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.0723957793,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.1493099624,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.2030761345,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.1077837471,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.1989136883,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.1014647154,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.046132753,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.0886754638,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'meteor')": 0.1152538017,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'cider')": 0.0078069275,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 's3_pyr')": 0.0860228614,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 's3_resp')": 0.0770267588,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'mover_score')": 0.123532899,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.0027276597,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'bleu')": 0.0871730268,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.137943473,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.0636072988,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.1169289068,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'blanc')": 0.1527217801,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": -0.0890990116,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": -0.0092925338,
  "('pearsonr', 'consistency', 'PreCalc', 'PreCalc', 'supert')": 0.1622601214,
  "('pearsonr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.4532633113,
  "('pearsonr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.2350173048,
  "('pearsonr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.3678161381,
  "('pearsonr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.4531394554,
  "('pearsonr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.235242973,
  "('pearsonr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.3680214564,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.3952308434,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.3743485779,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.4616943085,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.3276489806,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.2973357373,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.3342643611,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.3945629685,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.3492899182,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.4402965158,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.3942776014,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.3770652543,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.4637232353,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.3631782531,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.3394488358,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.3839116293,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'meteor')": 0.3650724764,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'cider')": 0.0300168335,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 's3_pyr')": 0.3591783447,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 's3_resp')": 0.3182991777,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'mover_score')": 0.3093894778,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.2014758225,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'bleu')": 0.3022943936,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.326301237,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.2890328972,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.3463690254,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'blanc')": 0.260111342,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.094107616,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.1875533817,
  "('pearsonr', 'relevance', 'PreCalc', 'PreCalc', 'supert')": 0.4128488176,
  "('pearsonr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.4831067095,
  "('pearsonr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.2385333687,
  "('pearsonr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.3854048414,
  "('pearsonr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.483072538,
  "('pearsonr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.238505778,
  "('pearsonr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.3854775344,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.3048027386,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.3326513894,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.3702920878,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.2278147457,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.2268289433,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.2392526981,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.2832601399,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.2879109866,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.3291801202,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.301716385,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.3312166396,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.3680082165,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.2340597734,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.2466198291,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.2580962864,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'meteor')": 0.2661959991,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'cider')": -0.0730350483,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 's3_pyr')": 0.2769539176,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 's3_resp')": 0.2485990889,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'mover_score')": 0.1818215858,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.1417483741,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'bleu')": 0.1638741634,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.2058824925,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.2944893795,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.2755968345,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'blanc')": 0.2103912794,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.0299313822,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.1182168612,
  "('pearsonr', 'coherence', 'PreCalc', 'PreCalc', 'supert')": 0.3238257805,
  "('pearsonr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.3318559373,
  "('pearsonr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.2403323636,
  "('pearsonr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.3110918896,
  "('pearsonr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.3318208557,
  "('pearsonr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.2399674912,
  "('pearsonr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.3108395986,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.1192631956,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.0583407253,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.1116405585,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.0922183945,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.0519174599,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.0802845221,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.137395204,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.0734994921,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.1261982409,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.1272196026,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.0518449744,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.1159383725,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.1233496196,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.0764509577,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.1127036235,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'meteor')": 0.0952834881,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'cider')": 0.0994879524,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 's3_pyr')": 0.0689644068,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 's3_resp')": 0.0524669427,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'mover_score')": 0.143413337,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.0229436054,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'bleu')": 0.1012940427,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.2116995809,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.1123291499,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.1866897852,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'blanc')": 0.1940961232,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.2498227398,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.2569688642,
  "('pearsonr', 'fluency', 'PreCalc', 'PreCalc', 'supert')": 0.1849887562,
  "('kendalltau', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.2949350279,
  "('kendalltau', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.1782664,
  "('kendalltau', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.2386403752,
  "('kendalltau', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.2957508924,
  "('kendalltau', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.1770426032,
  "('kendalltau', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.238232443,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.1378811057,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.0848499112,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.1456318187,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.0779150627,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.0501756686,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.0758754014,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.1150368988,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.0669008915,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.1223796796,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.1484873446,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.0917847597,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.1505270059,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.0807705885,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.0416090911,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.07383574,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'meteor')": 0.1044306599,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'cider')": -0.0473201428,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 's3_pyr')": 0.0856657757,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 's3_resp')": 0.0742436723,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'mover_score')": 0.1227876119,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.0057110517,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'bleu')": 0.0620057043,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.1085099826,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.0509915332,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.0901530306,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'blanc')": 0.0620057043,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": -0.0832181821,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": -0.0004079323,
  "('kendalltau', 'consistency', 'PreCalc', 'PreCalc', 'supert')": 0.0775071304,
  "('kendalltau', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.3498194315,
  "('kendalltau', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.158492929,
  "('kendalltau', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.2569936496,
  "('kendalltau', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.3498194315,
  "('kendalltau', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.1605196928,
  "('kendalltau', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.2586150606,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.2938807507,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.2424009502,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.3344160267,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.2407795392,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.2055138491,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.2379420699,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.2983396311,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.234293895,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.328741088,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.3003663949,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.2452384196,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.3368481432,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.2703702907,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.2322671313,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.2772612876,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'meteor')": 0.244427714,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'cider')": -0.0060802914,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 's3_pyr')": 0.2338885423,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 's3_resp')": 0.2156476681,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'mover_score')": 0.2282136037,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.13660388,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'bleu')": 0.2298350147,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.2492919472,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.1901104443,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.2549668858,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'blanc')": 0.1852462111,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.0587761501,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.1122827144,
  "('kendalltau', 'relevance', 'PreCalc', 'PreCalc', 'supert')": 0.29671822,
  "('kendalltau', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.3389053491,
  "('kendalltau', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.1638819052,
  "('kendalltau', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.257875977,
  "('kendalltau', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.3380950554,
  "('kendalltau', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.1671230801,
  "('kendalltau', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.2586862707,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.2193870252,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.2084480599,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.2566605364,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.1432194153,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.1367370656,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.1415988279,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.1902164512,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.184949542,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.2254642281,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.2246539344,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.2137149691,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.2546348021,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.15294294,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.1505120588,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.1719848424,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'meteor')": 0.1626664646,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'cider')": -0.0873091485,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 's3_pyr')": 0.1695539613,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 's3_resp')": 0.1505120588,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'mover_score')": 0.1367370656,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.0808267987,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'bleu')": 0.1164797225,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.1464605902,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.1829238077,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.1934576261,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'blanc')": 0.1363319187,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.0010128672,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.0634054837,
  "('kendalltau', 'coherence', 'PreCalc', 'PreCalc', 'supert')": 0.2586862707,
  "('kendalltau', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.2004325362,
  "('kendalltau', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.1377592153,
  "('kendalltau', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.1967698097,
  "('kendalltau', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.199618597,
  "('kendalltau', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.1373522456,
  "('kendalltau', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.1967698097,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.0665395323,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.0030522721,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.0225868137,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.0323540845,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.0075289379,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.0115986341,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.0669465019,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.0168892391,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.0307262061,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.0685743804,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.0034592417,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.0290983276,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.0628768058,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.0343889326,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.0437492338,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'meteor')": 0.0331680238,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'cider')": 0.0555513527,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 's3_pyr')": 0.0038662114,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 's3_resp')": 0.0099707556,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'mover_score')": 0.1426428507,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.053109535,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'bleu')": 0.0172962087,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.1279919445,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.0356098415,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.0848531651,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'blanc')": 0.1035737675,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.1418289114,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.1650261796,
  "('kendalltau', 'fluency', 'PreCalc', 'PreCalc', 'supert')": 0.096655284,
  "('spearmanr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.4339377339,
  "('spearmanr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.2555442451,
  "('spearmanr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.3460767644,
  "('spearmanr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.4346281344,
  "('spearmanr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.2556523078,
  "('spearmanr', 'consistency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.3453743569,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.2061475894,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.1221648697,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.2077745332,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.1082487968,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.0702707651,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.1061295674,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.1770006808,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.0901783138,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.1749655002,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.2271297614,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.1319325361,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.2153689388,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.1215705249,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.0620760112,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.1150147218,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'meteor')": 0.1464669677,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'cider')": -0.0587620888,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 's3_pyr')": 0.1190190448,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 's3_resp')": 0.1034700245,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'mover_score')": 0.1808489132,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.0106501783,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'bleu')": 0.0891577218,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.162352183,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.0743771473,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.1307618569,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'blanc')": 0.0930299681,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": -0.1261992101,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": -0.0061235524,
  "('spearmanr', 'consistency', 'PreCalc', 'PreCalc', 'supert')": 0.1000780568,
  "('spearmanr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.501491341,
  "('spearmanr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.2377557347,
  "('spearmanr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.379645803,
  "('spearmanr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.5018154143,
  "('spearmanr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.2422927601,
  "('spearmanr', 'relevance', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.3815242275,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.4400134465,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.3574647899,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.4976324689,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.3615157054,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.308475718,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.3549862297,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.4444724543,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.3467163607,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.4929334069,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.4492795407,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.3637362073,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.5020914767,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.3979559412,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.3360579518,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.4087523813,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'meteor')": 0.3621578505,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'cider')": -0.0024185466,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 's3_pyr')": 0.3448379361,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 's3_resp')": 0.3226269162,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'mover_score')": 0.3586230517,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.1991250038,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'bleu')": 0.3457681463,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.3731223286,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.2884131837,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.386787417,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'blanc')": 0.2642577243,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.0886580374,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.1650613052,
  "('spearmanr', 'relevance', 'PreCalc', 'PreCalc', 'supert')": 0.417724409,
  "('spearmanr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.4851890993,
  "('spearmanr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.2289268707,
  "('spearmanr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.3765798114,
  "('spearmanr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.4849910605,
  "('spearmanr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.2324615635,
  "('spearmanr', 'coherence', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.3785842042,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.3272501425,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.3076803068,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.3796584148,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.2157122806,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.2126696842,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.2208252828,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.2919632261,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.2723933904,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.3363299222,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.3395525539,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.3139155289,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.3839732605,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.2381266739,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.2331516988,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.2561602086,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'meteor')": 0.2536457157,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'cider')": -0.1195134252,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 's3_pyr')": 0.2542398322,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 's3_resp')": 0.2348440305,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'mover_score')": 0.2130657619,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.1128461184,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'bleu')": 0.1721017327,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.215622263,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.2770983125,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.2899888391,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'blanc')": 0.2000852176,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.0059351633,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.0952146625,
  "('spearmanr', 'coherence', 'PreCalc', 'PreCalc', 'supert')": 0.356445865,
  "('spearmanr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'P')": 0.2807296743,
  "('spearmanr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'R')": 0.1853143585,
  "('spearmanr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-entropy', 'F')": 0.2683585768,
  "('spearmanr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'P')": 0.2803935358,
  "('spearmanr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'R')": 0.1856985168,
  "('spearmanr', 'fluency', 'new', 'bertscore-sentence-pagerank-cos-deberta-large-sum', 'F')": 0.2691929206,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.1027083208,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.0055762977,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.0399704698,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.0591123572,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.0105343407,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.0254444844,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.1020180364,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.0297842726,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.0593224437,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_p')": 0.1084286779,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_r')": 0.0107264198,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_1_f')": 0.0435779562,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_p')": 0.0972640775,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_r')": 0.0608110571,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'rouge_we_2_f')": 0.0731461398,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'meteor')": 0.059034325,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'cider')": 0.0774619181,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 's3_pyr')": 0.0239198561,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 's3_resp')": 0.0190218379,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'mover_score')": 0.2030816795,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'sentence_movers_glove_sms')": 0.070385002,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'bleu')": 0.0299763517,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_precision')": 0.192967512,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_recall')": 0.059376466,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'bert_score_f1')": 0.1297254532,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'blanc')": 0.1429669093,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'summaqa_avg_prob')": 0.2112690531,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'summaqa_avg_fscore')": 0.2447028295,
  "('spearmanr', 'fluency', 'PreCalc', 'PreCalc', 'supert')": 0.1359740279
}