{
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore', 'precision')": 0.5112889967,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore', 'recall')": 0.2848803479,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore', 'f1')": 0.4300020575,
  "('pearsonr', 'InformativenessRating', 'new', 'bertscore', 'precision')": 0.3897721652,
  "('pearsonr', 'InformativenessRating', 'new', 'bertscore', 'recall')": 0.1802509509,
  "('pearsonr', 'InformativenessRating', 'new', 'bertscore', 'f1')": 0.2996584896,
  "('pearsonr', 'InformativenessRating', 'trad', 'rouge', 'rouge1')": 0.3682887228,
  "('pearsonr', 'InformativenessRating', 'trad', 'rouge', 'rouge2')": 0.4137822801,
  "('pearsonr', 'InformativenessRating', 'trad', 'rouge', 'rougeL')": 0.3585385816,
  "('pearsonr', 'InformativenessRating', 'trad', 'rouge', 'rougeLsum')": 0.3585385816,
  "('pearsonr', 'InformativenessRating', 'new', 'rouge', 'rouge1')": 0.109365694,
  "('pearsonr', 'InformativenessRating', 'new', 'rouge', 'rouge2')": 0.128017581,
  "('pearsonr', 'InformativenessRating', 'new', 'rouge', 'rougeL')": 0.1041501834,
  "('pearsonr', 'InformativenessRating', 'new', 'rouge', 'rougeLsum')": 0.1041501834,
  "('pearsonr', 'InformativenessRating', 'trad', 'bleurt', 'scores')": 0.3850494738,
  "('pearsonr', 'InformativenessRating', 'new', 'bleurt', 'scores')": 0.3782291358,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore', 'precision')": 0.486701645,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore', 'recall')": 0.301077122,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore', 'f1')": 0.4296951492,
  "('pearsonr', 'RelevanceRating', 'new', 'bertscore', 'precision')": 0.259290788,
  "('pearsonr', 'RelevanceRating', 'new', 'bertscore', 'recall')": 0.1216522428,
  "('pearsonr', 'RelevanceRating', 'new', 'bertscore', 'f1')": 0.2016132674,
  "('pearsonr', 'RelevanceRating', 'trad', 'rouge', 'rouge1')": 0.3368560592,
  "('pearsonr', 'RelevanceRating', 'trad', 'rouge', 'rouge2')": 0.3516944853,
  "('pearsonr', 'RelevanceRating', 'trad', 'rouge', 'rougeL')": 0.3275107651,
  "('pearsonr', 'RelevanceRating', 'trad', 'rouge', 'rougeLsum')": 0.3275107651,
  "('pearsonr', 'RelevanceRating', 'new', 'rouge', 'rouge1')": 0.0017512998,
  "('pearsonr', 'RelevanceRating', 'new', 'rouge', 'rouge2')": 0.0178252862,
  "('pearsonr', 'RelevanceRating', 'new', 'rouge', 'rougeL')": 0.0019199939,
  "('pearsonr', 'RelevanceRating', 'new', 'rouge', 'rougeLsum')": 0.0019199939,
  "('pearsonr', 'RelevanceRating', 'trad', 'bleurt', 'scores')": 0.2997698749,
  "('pearsonr', 'RelevanceRating', 'new', 'bleurt', 'scores')": 0.3009886523,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore', 'precision')": 0.4069950038,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore', 'recall')": 0.1487800546,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore', 'f1')": 0.297621684,
  "('pearsonr', 'CoherenceRating', 'new', 'bertscore', 'precision')": 0.1316696862,
  "('pearsonr', 'CoherenceRating', 'new', 'bertscore', 'recall')": -0.1806152724,
  "('pearsonr', 'CoherenceRating', 'new', 'bertscore', 'f1')": -0.0532916924,
  "('pearsonr', 'CoherenceRating', 'trad', 'rouge', 'rouge1')": 0.2885451161,
  "('pearsonr', 'CoherenceRating', 'trad', 'rouge', 'rouge2')": 0.2788903655,
  "('pearsonr', 'CoherenceRating', 'trad', 'rouge', 'rougeL')": 0.2390151945,
  "('pearsonr', 'CoherenceRating', 'trad', 'rouge', 'rougeLsum')": 0.2390151945,
  "('pearsonr', 'CoherenceRating', 'new', 'rouge', 'rouge1')": -0.2887243389,
  "('pearsonr', 'CoherenceRating', 'new', 'rouge', 'rouge2')": -0.2744088552,
  "('pearsonr', 'CoherenceRating', 'new', 'rouge', 'rougeL')": -0.2926162401,
  "('pearsonr', 'CoherenceRating', 'new', 'rouge', 'rougeLsum')": -0.2926162401,
  "('pearsonr', 'CoherenceRating', 'trad', 'bleurt', 'scores')": 0.2097816908,
  "('pearsonr', 'CoherenceRating', 'new', 'bleurt', 'scores')": 0.0224950557,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore', 'precision')": 0.3475024614,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore', 'recall')": 0.1493912674,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore', 'f1')": 0.2688805833,
  "('pearsonr', 'FluencyRating', 'new', 'bertscore', 'precision')": 0.1067164663,
  "('pearsonr', 'FluencyRating', 'new', 'bertscore', 'recall')": -0.2262928235,
  "('pearsonr', 'FluencyRating', 'new', 'bertscore', 'f1')": -0.0955450939,
  "('pearsonr', 'FluencyRating', 'trad', 'rouge', 'rouge1')": 0.1949138732,
  "('pearsonr', 'FluencyRating', 'trad', 'rouge', 'rouge2')": 0.1878568304,
  "('pearsonr', 'FluencyRating', 'trad', 'rouge', 'rougeL')": 0.1480021708,
  "('pearsonr', 'FluencyRating', 'trad', 'rouge', 'rougeLsum')": 0.1480021708,
  "('pearsonr', 'FluencyRating', 'new', 'rouge', 'rouge1')": -0.3538668305,
  "('pearsonr', 'FluencyRating', 'new', 'rouge', 'rouge2')": -0.3368149799,
  "('pearsonr', 'FluencyRating', 'new', 'rouge', 'rougeL')": -0.3617700553,
  "('pearsonr', 'FluencyRating', 'new', 'rouge', 'rougeLsum')": -0.3617700553,
  "('pearsonr', 'FluencyRating', 'trad', 'bleurt', 'scores')": 0.1018477161,
  "('pearsonr', 'FluencyRating', 'new', 'bleurt', 'scores')": -0.0686688707,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore', 'precision')": 0.3473821575,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore', 'recall')": 0.1779832801,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore', 'f1')": 0.2706948279,
  "('kendalltau', 'InformativenessRating', 'new', 'bertscore', 'precision')": 0.3096107862,
  "('kendalltau', 'InformativenessRating', 'new', 'bertscore', 'recall')": 0.2157546514,
  "('kendalltau', 'InformativenessRating', 'new', 'bertscore', 'f1')": 0.2661164798,
  "('kendalltau', 'InformativenessRating', 'trad', 'rouge', 'rouge1')": 0.2478030877,
  "('kendalltau', 'InformativenessRating', 'trad', 'rouge', 'rouge2')": 0.2947311551,
  "('kendalltau', 'InformativenessRating', 'trad', 'rouge', 'rougeL')": 0.2466585007,
  "('kendalltau', 'InformativenessRating', 'trad', 'rouge', 'rougeLsum')": 0.2466585007,
  "('kendalltau', 'InformativenessRating', 'new', 'rouge', 'rouge1')": 0.1058742984,
  "('kendalltau', 'InformativenessRating', 'new', 'rouge', 'rouge2')": 0.1310552127,
  "('kendalltau', 'InformativenessRating', 'new', 'rouge', 'rougeL')": 0.1241876906,
  "('kendalltau', 'InformativenessRating', 'new', 'rouge', 'rougeLsum')": 0.1241876906,
  "('kendalltau', 'InformativenessRating', 'trad', 'bleurt', 'scores')": 0.2729840019,
  "('kendalltau', 'InformativenessRating', 'new', 'bleurt', 'scores')": 0.2203329994,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore', 'precision')": 0.3323099388,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore', 'recall')": 0.2030465203,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore', 'f1')": 0.2888408246,
  "('kendalltau', 'RelevanceRating', 'new', 'bertscore', 'precision')": 0.2041904443,
  "('kendalltau', 'RelevanceRating', 'new', 'bertscore', 'recall')": 0.2259250014,
  "('kendalltau', 'RelevanceRating', 'new', 'bertscore', 'f1')": 0.2110539887,
  "('kendalltau', 'RelevanceRating', 'trad', 'rouge', 'rouge1')": 0.2522352547,
  "('kendalltau', 'RelevanceRating', 'trad', 'rouge', 'rouge2')": 0.2888408246,
  "('kendalltau', 'RelevanceRating', 'trad', 'rouge', 'rougeL')": 0.2533791788,
  "('kendalltau', 'RelevanceRating', 'trad', 'rouge', 'rougeLsum')": 0.2533791788,
  "('kendalltau', 'RelevanceRating', 'new', 'rouge', 'rouge1')": 0.0760709498,
  "('kendalltau', 'RelevanceRating', 'new', 'rouge', 'rouge2')": 0.1012372791,
  "('kendalltau', 'RelevanceRating', 'new', 'rouge', 'rougeL')": 0.0863662664,
  "('kendalltau', 'RelevanceRating', 'new', 'rouge', 'rougeLsum')": 0.0863662664,
  "('kendalltau', 'RelevanceRating', 'trad', 'bleurt', 'scores')": 0.1996147481,
  "('kendalltau', 'RelevanceRating', 'new', 'bleurt', 'scores')": 0.2991361411,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore', 'precision')": 0.2808333562,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore', 'recall')": 0.098949431,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore', 'f1')": 0.1916072797,
  "('kendalltau', 'CoherenceRating', 'new', 'bertscore', 'precision')": 0.1138204437,
  "('kendalltau', 'CoherenceRating', 'new', 'bertscore', 'recall')": -0.0154429748,
  "('kendalltau', 'CoherenceRating', 'new', 'bertscore', 'f1')": 0.0326018356,
  "('kendalltau', 'CoherenceRating', 'trad', 'rouge', 'rouge1')": 0.2076222165,
  "('kendalltau', 'CoherenceRating', 'trad', 'rouge', 'rouge2')": 0.2236371533,
  "('kendalltau', 'CoherenceRating', 'trad', 'rouge', 'rougeL')": 0.1744484188,
  "('kendalltau', 'CoherenceRating', 'trad', 'rouge', 'rougeLsum')": 0.1744484188,
  "('kendalltau', 'CoherenceRating', 'new', 'rouge', 'rouge1')": -0.1607213301,
  "('kendalltau', 'CoherenceRating', 'new', 'rouge', 'rouge2')": -0.1401306971,
  "('kendalltau', 'CoherenceRating', 'new', 'rouge', 'rougeL')": -0.1504260136,
  "('kendalltau', 'CoherenceRating', 'new', 'rouge', 'rougeLsum')": -0.1504260136,
  "('kendalltau', 'CoherenceRating', 'trad', 'bleurt', 'scores')": 0.1515699377,
  "('kendalltau', 'CoherenceRating', 'new', 'bleurt', 'scores')": 0.0268822154,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore', 'precision')": 0.2927598114,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore', 'recall')": 0.1223644524,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore', 'f1')": 0.2172826725,
  "('kendalltau', 'FluencyRating', 'new', 'bertscore', 'precision')": 0.0811951039,
  "('kendalltau', 'FluencyRating', 'new', 'bertscore', 'recall')": -0.0331641974,
  "('kendalltau', 'FluencyRating', 'new', 'bertscore', 'f1')": 0.0148667092,
  "('kendalltau', 'FluencyRating', 'trad', 'rouge', 'rouge1')": 0.1669645799,
  "('kendalltau', 'FluencyRating', 'trad', 'rouge', 'rouge2')": 0.170395359,
  "('kendalltau', 'FluencyRating', 'trad', 'rouge', 'rougeL')": 0.1360875686,
  "('kendalltau', 'FluencyRating', 'trad', 'rouge', 'rougeLsum')": 0.1360875686,
  "('kendalltau', 'FluencyRating', 'new', 'rouge', 'rouge1')": -0.2149954865,
  "('kendalltau', 'FluencyRating', 'new', 'rouge', 'rouge2')": -0.2081339284,
  "('kendalltau', 'FluencyRating', 'new', 'rouge', 'rougeL')": -0.2104211145,
  "('kendalltau', 'FluencyRating', 'new', 'rouge', 'rougeLsum')": -0.2104211145,
  "('kendalltau', 'FluencyRating', 'trad', 'bleurt', 'scores')": 0.1109285223,
  "('kendalltau', 'FluencyRating', 'new', 'bleurt', 'scores')": -0.0423129415,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore', 'precision')": 0.5051454033,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore', 'recall')": 0.2481367224,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore', 'f1')": 0.3918958254,
  "('spearmanr', 'InformativenessRating', 'new', 'bertscore', 'precision')": 0.4396764676,
  "('spearmanr', 'InformativenessRating', 'new', 'bertscore', 'recall')": 0.3109913505,
  "('spearmanr', 'InformativenessRating', 'new', 'bertscore', 'f1')": 0.3602460171,
  "('spearmanr', 'InformativenessRating', 'trad', 'rouge', 'rouge1')": 0.367671763,
  "('spearmanr', 'InformativenessRating', 'trad', 'rouge', 'rouge2')": 0.4162589468,
  "('spearmanr', 'InformativenessRating', 'trad', 'rouge', 'rougeL')": 0.3596341579,
  "('spearmanr', 'InformativenessRating', 'trad', 'rouge', 'rougeLsum')": 0.3596341579,
  "('spearmanr', 'InformativenessRating', 'new', 'rouge', 'rouge1')": 0.1843921171,
  "('spearmanr', 'InformativenessRating', 'new', 'rouge', 'rouge2')": 0.2128435705,
  "('spearmanr', 'InformativenessRating', 'new', 'rouge', 'rougeL')": 0.2039994237,
  "('spearmanr', 'InformativenessRating', 'new', 'rouge', 'rougeLsum')": 0.2039994237,
  "('spearmanr', 'InformativenessRating', 'trad', 'bleurt', 'scores')": 0.3986262768,
  "('spearmanr', 'InformativenessRating', 'new', 'bleurt', 'scores')": 0.3245078768,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore', 'precision')": 0.473532256,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore', 'recall')": 0.2756128528,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore', 'f1')": 0.404239602,
  "('spearmanr', 'RelevanceRating', 'new', 'bertscore', 'precision')": 0.3042367552,
  "('spearmanr', 'RelevanceRating', 'new', 'bertscore', 'recall')": 0.3233471741,
  "('spearmanr', 'RelevanceRating', 'new', 'bertscore', 'f1')": 0.2926926157,
  "('spearmanr', 'RelevanceRating', 'trad', 'rouge', 'rouge1')": 0.3585359365,
  "('spearmanr', 'RelevanceRating', 'trad', 'rouge', 'rouge2')": 0.3931127206,
  "('spearmanr', 'RelevanceRating', 'trad', 'rouge', 'rougeL')": 0.3579795925,
  "('spearmanr', 'RelevanceRating', 'trad', 'rouge', 'rougeLsum')": 0.3579795925,
  "('spearmanr', 'RelevanceRating', 'new', 'rouge', 'rouge1')": 0.1107681045,
  "('spearmanr', 'RelevanceRating', 'new', 'rouge', 'rouge2')": 0.1438705768,
  "('spearmanr', 'RelevanceRating', 'new', 'rouge', 'rougeL')": 0.1267908138,
  "('spearmanr', 'RelevanceRating', 'new', 'rouge', 'rougeLsum')": 0.1267908138,
  "('spearmanr', 'RelevanceRating', 'trad', 'bleurt', 'scores')": 0.3005092499,
  "('spearmanr', 'RelevanceRating', 'new', 'bleurt', 'scores')": 0.4267437196,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore', 'precision')": 0.4098173126,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore', 'recall')": 0.1392199693,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore', 'f1')": 0.2896476188,
  "('spearmanr', 'CoherenceRating', 'new', 'bertscore', 'precision')": 0.1658625443,
  "('spearmanr', 'CoherenceRating', 'new', 'bertscore', 'recall')": -0.0264757113,
  "('spearmanr', 'CoherenceRating', 'new', 'bertscore', 'f1')": 0.0434401902,
  "('spearmanr', 'CoherenceRating', 'trad', 'rouge', 'rouge1')": 0.3128416768,
  "('spearmanr', 'CoherenceRating', 'trad', 'rouge', 'rouge2')": 0.3166239213,
  "('spearmanr', 'CoherenceRating', 'trad', 'rouge', 'rougeL')": 0.268567168,
  "('spearmanr', 'CoherenceRating', 'trad', 'rouge', 'rougeLsum')": 0.268567168,
  "('spearmanr', 'CoherenceRating', 'new', 'rouge', 'rouge1')": -0.2294932454,
  "('spearmanr', 'CoherenceRating', 'new', 'rouge', 'rouge2')": -0.2024613217,
  "('spearmanr', 'CoherenceRating', 'new', 'rouge', 'rougeL')": -0.2212056803,
  "('spearmanr', 'CoherenceRating', 'new', 'rouge', 'rougeLsum')": -0.2212056803,
  "('spearmanr', 'CoherenceRating', 'trad', 'bleurt', 'scores')": 0.2389766672,
  "('spearmanr', 'CoherenceRating', 'new', 'bleurt', 'scores')": 0.0329833966,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore', 'precision')": 0.4341141111,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore', 'recall')": 0.1720993093,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore', 'f1')": 0.3247859946,
  "('spearmanr', 'FluencyRating', 'new', 'bertscore', 'precision')": 0.1311047421,
  "('spearmanr', 'FluencyRating', 'new', 'bertscore', 'recall')": -0.0538436107,
  "('spearmanr', 'FluencyRating', 'new', 'bertscore', 'f1')": 0.0123762432,
  "('spearmanr', 'FluencyRating', 'trad', 'rouge', 'rouge1')": 0.262876967,
  "('spearmanr', 'FluencyRating', 'trad', 'rouge', 'rouge2')": 0.2499444882,
  "('spearmanr', 'FluencyRating', 'trad', 'rouge', 'rougeL')": 0.2082546264,
  "('spearmanr', 'FluencyRating', 'trad', 'rouge', 'rougeLsum')": 0.2082546264,
  "('spearmanr', 'FluencyRating', 'new', 'rouge', 'rouge1')": -0.3016187799,
  "('spearmanr', 'FluencyRating', 'new', 'rouge', 'rouge2')": -0.285376699,
  "('spearmanr', 'FluencyRating', 'new', 'rouge', 'rougeL')": -0.3011181678,
  "('spearmanr', 'FluencyRating', 'new', 'rouge', 'rougeLsum')": -0.3011181678,
  "('spearmanr', 'FluencyRating', 'trad', 'bleurt', 'scores')": 0.1541607097,
  "('spearmanr', 'FluencyRating', 'new', 'bleurt', 'scores')": -0.0630771224
}