{
    "newsroom": {
        "rouge1": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.1301613327981303,
                    "(Informativeness, scores)": 0.1716623628681213,
                    "(Fluency, scores)": 0.09931131965458487,
                    "(Relevance, scores)": 0.22263496414191486
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.12762067166136826,
                    "(Informativeness, scores)": 0.15689137345826173,
                    "(Fluency, scores)": 0.09419723509738352,
                    "(Relevance, scores)": 0.1728205331745226
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.18061345208594612,
                    "(Informativeness, scores)": 0.2226987943398279,
                    "(Fluency, scores)": 0.13308575649076185,
                    "(Relevance, scores)": 0.2405201459687705
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.288603070787511,
                    "(Informativeness, scores)": 0.4792943575227374,
                    "(Fluency, scores)": 0.23154698866540255,
                    "(Relevance, scores)": 0.41263184578791706
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.3055149391307713,
                    "(Informativeness, scores)": 0.4718993460598713,
                    "(Fluency, scores)": 0.25387028120278127,
                    "(Relevance, scores)": 0.41830540215002515
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.4242339946437663,
                    "(Informativeness, scores)": 0.6317320309592711,
                    "(Fluency, scores)": 0.3538325705283334,
                    "(Relevance, scores)": 0.5626276450293708
                }
            }
        },
        "rouge2": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.06055476722237475,
                    "(Informativeness, scores)": 0.1264604861914584,
                    "(Fluency, scores)": 0.04666160017111359,
                    "(Relevance, scores)": 0.16259964402020746
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.13632573448061952,
                    "(Informativeness, scores)": 0.21815046512261013,
                    "(Fluency, scores)": 0.12205424214209497,
                    "(Relevance, scores)": 0.2178940859332294
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.17385375422639776,
                    "(Informativeness, scores)": 0.2817900495002393,
                    "(Fluency, scores)": 0.1563823595708934,
                    "(Relevance, scores)": 0.2776920226062856
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.3214484917116289,
                    "(Informativeness, scores)": 0.5034985225762479,
                    "(Fluency, scores)": 0.26628243742018176,
                    "(Relevance, scores)": 0.44094846168692126
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.34210329417389496,
                    "(Informativeness, scores)": 0.5050840203717053,
                    "(Fluency, scores)": 0.2937321850820414,
                    "(Relevance, scores)": 0.4505317685947166
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.46580011899383356,
                    "(Informativeness, scores)": 0.6638642073254242,
                    "(Fluency, scores)": 0.40076188090376136,
                    "(Relevance, scores)": 0.5961589466746081
                }
            }
        },
        "rougeL": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.08202572228590645,
                    "(Informativeness, scores)": 0.13513062413512436,
                    "(Fluency, scores)": 0.0520951377161758,
                    "(Relevance, scores)": 0.1869119809187616
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.09535757031735373,
                    "(Informativeness, scores)": 0.12622794284865455,
                    "(Fluency, scores)": 0.0640200084081104,
                    "(Relevance, scores)": 0.14796342277360888
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.13498056155332733,
                    "(Informativeness, scores)": 0.18078647317969523,
                    "(Fluency, scores)": 0.09038894572560736,
                    "(Relevance, scores)": 0.20503849125550566
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.31108935314485503,
                    "(Informativeness, scores)": 0.4863120419748046,
                    "(Fluency, scores)": 0.2514811925453072,
                    "(Relevance, scores)": 0.4240402886722537
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.32505780561750136,
                    "(Informativeness, scores)": 0.4847984633574314,
                    "(Fluency, scores)": 0.2766932184398713,
                    "(Relevance, scores)": 0.4305452552021397
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.4509018162476715,
                    "(Informativeness, scores)": 0.6460813264384901,
                    "(Fluency, scores)": 0.3832246703377784,
                    "(Relevance, scores)": 0.5784587763838158
                }
            }
        },
        "rougeLsum": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.08202572228590645,
                    "(Informativeness, scores)": 0.13513062413512436,
                    "(Fluency, scores)": 0.0520951377161758,
                    "(Relevance, scores)": 0.1869119809187616
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.09535757031735373,
                    "(Informativeness, scores)": 0.12622794284865455,
                    "(Fluency, scores)": 0.0640200084081104,
                    "(Relevance, scores)": 0.14796342277360888
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.13498056155332733,
                    "(Informativeness, scores)": 0.18078647317969523,
                    "(Fluency, scores)": 0.09038894572560736,
                    "(Relevance, scores)": 0.20503849125550566
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.31108935314485503,
                    "(Informativeness, scores)": 0.4863120419748046,
                    "(Fluency, scores)": 0.2514811925453072,
                    "(Relevance, scores)": 0.4240402886722537
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.32505780561750136,
                    "(Informativeness, scores)": 0.4847984633574314,
                    "(Fluency, scores)": 0.2766932184398713,
                    "(Relevance, scores)": 0.4305452552021397
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.4509018162476715,
                    "(Informativeness, scores)": 0.6460813264384901,
                    "(Fluency, scores)": 0.3832246703377784,
                    "(Relevance, scores)": 0.5784587763838158
                }
            }
        },
        "bertscore": {
            "trad": {
                "pearsonr": {
                    "(Coherence, precision)": 0.04141656283585623,
                    "(Coherence, recall)": 0.37944527879097967,
                    "(Coherence, f1)": 0.26343869493950556,
                    "(Informativeness, precision)": 0.03237431371837886,
                    "(Informativeness, recall)": 0.43770915470840244,
                    "(Informativeness, f1)": 0.295318867775623,
                    "(Fluency, precision)": 0.0440260076580521,
                    "(Fluency, recall)": 0.3336608668965342,
                    "(Fluency, f1)": 0.23448925023352946,
                    "(Relevance, precision)": 0.0931539060092134,
                    "(Relevance, recall)": 0.4514910641831725,
                    "(Relevance, f1)": 0.33841053166885426
                },
                "kendalltau": {
                    "(Coherence, precision)": 0.019011424713182817,
                    "(Coherence, recall)": 0.2537829139984839,
                    "(Coherence, f1)": 0.1754611329248035,
                    "(Informativeness, precision)": 0.013035736919468213,
                    "(Informativeness, recall)": 0.2863986979913424,
                    "(Informativeness, f1)": 0.19414817000676265,
                    "(Fluency, precision)": 0.01825382562612475,
                    "(Fluency, recall)": 0.22235026354514964,
                    "(Fluency, f1)": 0.14829022276879733,
                    "(Relevance, precision)": 0.05526517120715931,
                    "(Relevance, recall)": 0.2904903932086664,
                    "(Relevance, f1)": 0.216033137954964
                },
                "spearmanr": {
                    "(Coherence, precision)": 0.02855265214368889,
                    "(Coherence, recall)": 0.35077076534116464,
                    "(Coherence, f1)": 0.2461261675942864,
                    "(Informativeness, precision)": 0.019019152309572497,
                    "(Informativeness, recall)": 0.40149918871673157,
                    "(Informativeness, f1)": 0.27437713645105904,
                    "(Fluency, precision)": 0.028088031664502567,
                    "(Fluency, recall)": 0.31073762771575925,
                    "(Fluency, f1)": 0.20893297151967924,
                    "(Relevance, precision)": 0.07805866567718353,
                    "(Relevance, recall)": 0.4018138619266075,
                    "(Relevance, f1)": 0.30069155825655564
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, precision)": 0.5913884829270248,
                    "(Coherence, recall)": 0.52189483903445,
                    "(Coherence, f1)": 0.602935755316456,
                    "(Informativeness, precision)": 0.6509037445699221,
                    "(Informativeness, recall)": 0.6469512514251693,
                    "(Informativeness, f1)": 0.7003153012044627,
                    "(Fluency, precision)": 0.5392243604048961,
                    "(Fluency, recall)": 0.4564149787427919,
                    "(Fluency, f1)": 0.5393741798536061,
                    "(Relevance, precision)": 0.6433591686837836,
                    "(Relevance, recall)": 0.6033019899004134,
                    "(Relevance, f1)": 0.6742682615603245
                },
                "kendalltau": {
                    "(Coherence, precision)": 0.43299787378365245,
                    "(Coherence, recall)": 0.39257763488075426,
                    "(Coherence, f1)": 0.43505642399740097,
                    "(Informativeness, precision)": 0.4591785104048141,
                    "(Informativeness, recall)": 0.4809327525596092,
                    "(Informativeness, f1)": 0.5017705188808319,
                    "(Fluency, precision)": 0.3997346342657992,
                    "(Fluency, recall)": 0.33124064184447966,
                    "(Fluency, f1)": 0.38585597221023726,
                    "(Relevance, precision)": 0.4372142685500582,
                    "(Relevance, recall)": 0.43628933370218614,
                    "(Relevance, f1)": 0.4628446999924082
                },
                "spearmanr": {
                    "(Coherence, precision)": 0.5794519199497279,
                    "(Coherence, recall)": 0.5290302619010436,
                    "(Coherence, f1)": 0.579682221463319,
                    "(Informativeness, precision)": 0.609271353573532,
                    "(Informativeness, recall)": 0.6409215814334008,
                    "(Informativeness, f1)": 0.6625452131939445,
                    "(Fluency, precision)": 0.5288494910673346,
                    "(Fluency, recall)": 0.45067336655230933,
                    "(Fluency, f1)": 0.5147867483783392,
                    "(Relevance, precision)": 0.5786121591879758,
                    "(Relevance, recall)": 0.5857147128273793,
                    "(Relevance, f1)": 0.6119381856132456
                }
            }
        },
        "bleurt": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.22908762329228566,
                    "(Informativeness, scores)": 0.336717068999185,
                    "(Fluency, scores)": 0.18690323764195094,
                    "(Relevance, scores)": 0.34858904223902387
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.1574669822328602,
                    "(Informativeness, scores)": 0.24009255061084747,
                    "(Fluency, scores)": 0.11999816912138213,
                    "(Relevance, scores)": 0.22019534477038838
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.21930094129311037,
                    "(Informativeness, scores)": 0.33404461968192556,
                    "(Fluency, scores)": 0.16620688198103933,
                    "(Relevance, scores)": 0.3094119325998322
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.4796695272822946,
                    "(Informativeness, scores)": 0.5689407830822455,
                    "(Fluency, scores)": 0.43647849256708104,
                    "(Relevance, scores)": 0.5165859564036228
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.3432450844642153,
                    "(Informativeness, scores)": 0.41516355260824994,
                    "(Fluency, scores)": 0.3059625183107066,
                    "(Relevance, scores)": 0.3732720620932174
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.4689640337994972,
                    "(Informativeness, scores)": 0.558822277952327,
                    "(Fluency, scores)": 0.4199665222944733,
                    "(Relevance, scores)": 0.5072675916931708
                }
            }
        },
        "bertscore-sentence": {
            "trad": {
                "pearsonr": {
                    "(Coherence, P)": 0.3014501975514774,
                    "(Coherence, R)": 0.3959894116654985,
                    "(Coherence, F)": 0.34848503515384366,
                    "(Informativeness, P)": 0.3874752652587383,
                    "(Informativeness, R)": 0.5080634943391205,
                    "(Informativeness, F)": 0.4457809745463051,
                    "(Fluency, P)": 0.2586518052366038,
                    "(Fluency, R)": 0.3488677660727319,
                    "(Fluency, F)": 0.30262434946486605,
                    "(Relevance, P)": 0.43564194864916334,
                    "(Relevance, R)": 0.5254570016085278,
                    "(Relevance, F)": 0.4821959870707306
                },
                "kendalltau": {
                    "(Coherence, P)": 0.20803466277764832,
                    "(Coherence, R)": 0.26468698631109533,
                    "(Coherence, F)": 0.23670905634327527,
                    "(Informativeness, P)": 0.26090619914697616,
                    "(Informativeness, R)": 0.33983409872346143,
                    "(Informativeness, F)": 0.29720346571345785,
                    "(Fluency, P)": 0.17500239369535173,
                    "(Fluency, R)": 0.22524395888986143,
                    "(Fluency, F)": 0.2005964937732969,
                    "(Relevance, P)": 0.286328186393242,
                    "(Relevance, R)": 0.35291492592050555,
                    "(Relevance, F)": 0.31918771388343425
                },
                "spearmanr": {
                    "(Coherence, P)": 0.2922503340655952,
                    "(Coherence, R)": 0.3666448131081752,
                    "(Coherence, F)": 0.3303872847098646,
                    "(Informativeness, P)": 0.3634241683415071,
                    "(Informativeness, R)": 0.46716202456275346,
                    "(Informativeness, F)": 0.4133276249389482,
                    "(Fluency, P)": 0.24826056490847864,
                    "(Fluency, R)": 0.3167273611232579,
                    "(Fluency, F)": 0.2828513463524536,
                    "(Relevance, P)": 0.3929076656726241,
                    "(Relevance, R)": 0.47624146524273936,
                    "(Relevance, F)": 0.4355521167913935
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, P)": 0.6420093899971999,
                    "(Coherence, R)": 0.4707240100527591,
                    "(Coherence, F)": 0.5509485618264295,
                    "(Informativeness, P)": 0.7068599311485388,
                    "(Informativeness, R)": 0.6370770438805435,
                    "(Informativeness, F)": 0.6986466628736088,
                    "(Fluency, P)": 0.5919915007921714,
                    "(Fluency, R)": 0.41553984658653187,
                    "(Fluency, F)": 0.4921763037722525,
                    "(Relevance, P)": 0.7493382508892218,
                    "(Relevance, R)": 0.6189331808011034,
                    "(Relevance, F)": 0.6985174403750464
                },
                "kendalltau": {
                    "(Coherence, P)": 0.4599703768447911,
                    "(Coherence, R)": 0.3221509993327448,
                    "(Coherence, F)": 0.3731546081580914,
                    "(Informativeness, P)": 0.4352450064949642,
                    "(Informativeness, R)": 0.4457690218925458,
                    "(Informativeness, F)": 0.4791962720328406,
                    "(Fluency, P)": 0.44054781803757204,
                    "(Fluency, R)": 0.2864448902360722,
                    "(Fluency, F)": 0.33911574956077045,
                    "(Relevance, P)": 0.450459888403456,
                    "(Relevance, R)": 0.4106832426505696,
                    "(Relevance, F)": 0.4493601235260625
                },
                "spearmanr": {
                    "(Coherence, P)": 0.6134452767630848,
                    "(Coherence, R)": 0.44222986643011347,
                    "(Coherence, F)": 0.5066475681304835,
                    "(Informativeness, P)": 0.5857378891557679,
                    "(Informativeness, R)": 0.5996269437322165,
                    "(Informativeness, F)": 0.6386625701739536,
                    "(Fluency, P)": 0.591170808572363,
                    "(Fluency, R)": 0.3945964218282078,
                    "(Fluency, F)": 0.4624801496005824,
                    "(Relevance, P)": 0.6001043893908033,
                    "(Relevance, R)": 0.5547699234102075,
                    "(Relevance, F)": 0.6013216259072565
                }
            }
        }
    },
    "realsumm_abs": {
        "rouge1": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5840501663551281
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.41054106736403634
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5728265389879345
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.3233123444275029
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.21543617665062453
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.31698043204022797
                }
            }
        },
        "rouge2": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5655386668052393
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.4129394700887854
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5758401967870274
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.32411722841106394
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.2173068213130148
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.32019622910470497
                }
            }
        },
        "rougeL": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5128340976719938
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.35970070962517414
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5103572079605415
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.32676399139344814
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.2174161106949151
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.3200441891567805
                }
            }
        },
        "rougeLsum": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5128340976719938
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.35970070962517414
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5103572079605415
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.32676399139344814
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.2174161106949151
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.3200441891567805
                }
            }
        },
        "bertscore": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, precision)": 0.31580603439450444,
                    "(litepyramid_recall, recall)": 0.5595098816305013,
                    "(litepyramid_recall, f1)": 0.47030027384692474
                },
                "kendalltau": {
                    "(litepyramid_recall, precision)": 0.2031300273828264,
                    "(litepyramid_recall, recall)": 0.37937132342619717,
                    "(litepyramid_recall, f1)": 0.31204659500979026
                },
                "spearmanr": {
                    "(litepyramid_recall, precision)": 0.29779648226000827,
                    "(litepyramid_recall, recall)": 0.534709292406836,
                    "(litepyramid_recall, f1)": 0.44785859004089656
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, precision)": 0.03676665314346844,
                    "(litepyramid_recall, recall)": 0.32484502436230644,
                    "(litepyramid_recall, f1)": 0.19142781893871183
                },
                "kendalltau": {
                    "(litepyramid_recall, precision)": 0.030788996956980917,
                    "(litepyramid_recall, recall)": 0.21789319268554563,
                    "(litepyramid_recall, f1)": 0.12937321203553842
                },
                "spearmanr": {
                    "(litepyramid_recall, precision)": 0.04570996068221977,
                    "(litepyramid_recall, recall)": 0.3207435821801964,
                    "(litepyramid_recall, f1)": 0.19286325468736723
                }
            }
        },
        "bleurt": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.563952586514187
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.3872695851067014
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.544854186997014
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.23286948740253804
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.1517981417498496
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.22489503658025942
                }
            }
        },
        "bertscore-sentence": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, P)": 0.2833377128730934,
                    "(litepyramid_recall, R)": 0.28908461520827905,
                    "(litepyramid_recall, F)": 0.3316108147496215
                },
                "kendalltau": {
                    "(litepyramid_recall, P)": 0.18283222627875154,
                    "(litepyramid_recall, R)": 0.20642901065751004,
                    "(litepyramid_recall, F)": 0.21531615374365878
                },
                "spearmanr": {
                    "(litepyramid_recall, P)": 0.26757820859262943,
                    "(litepyramid_recall, R)": 0.3004769680830865,
                    "(litepyramid_recall, F)": 0.3126901615061314
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, P)": 0.06159846993929814,
                    "(litepyramid_recall, R)": 0.3520037694452085,
                    "(litepyramid_recall, F)": 0.37448996192534034
                },
                "kendalltau": {
                    "(litepyramid_recall, P)": 0.05096063483837915,
                    "(litepyramid_recall, R)": 0.2263688793499535,
                    "(litepyramid_recall, F)": 0.24076803273150732
                },
                "spearmanr": {
                    "(litepyramid_recall, P)": 0.07565233829396732,
                    "(litepyramid_recall, R)": 0.33046118435804156,
                    "(litepyramid_recall, F)": 0.34953079586803276
                }
            }
        }
    },
    "realsumm_ext": {
        "rouge1": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.2547127415815572
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.14861665986848718
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.20988246942755948
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.17056769992946544
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.11668324576907085
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.1707065957005945
                }
            }
        },
        "rouge2": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.2971352930625117
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.19116419778764435
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.2712405237874062
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.16979206605718555
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.119155874680575
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.1740230088329624
                }
            }
        },
        "rougeL": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.24168161174441327
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.15966207551799702
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.2316855126892376
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.17064807216820463
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.11848948672705939
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.17271776887656132
                }
            }
        },
        "rougeLsum": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.24168161174441327
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.15966207551799702
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.2316855126892376
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.17064807216820463
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.11848948672705939
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.17271776887656132
                }
            }
        },
        "bertscore": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, precision)": 0.14313484851752228,
                    "(litepyramid_recall, recall)": 0.28390693363786706,
                    "(litepyramid_recall, f1)": 0.22501967722568422
                },
                "kendalltau": {
                    "(litepyramid_recall, precision)": 0.0852081487704314,
                    "(litepyramid_recall, recall)": 0.17326370194310256,
                    "(litepyramid_recall, f1)": 0.137457163618344
                },
                "spearmanr": {
                    "(litepyramid_recall, precision)": 0.12283152190936857,
                    "(litepyramid_recall, recall)": 0.2495630211183389,
                    "(litepyramid_recall, f1)": 0.1977896247797331
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, precision)": 0.03531298950375657,
                    "(litepyramid_recall, recall)": 0.09073697255187785,
                    "(litepyramid_recall, f1)": 0.06718812402723712
                },
                "kendalltau": {
                    "(litepyramid_recall, precision)": 0.02440550827330555,
                    "(litepyramid_recall, recall)": 0.0490936110316113,
                    "(litepyramid_recall, f1)": 0.038002033371180736
                },
                "spearmanr": {
                    "(litepyramid_recall, precision)": 0.03505721245130046,
                    "(litepyramid_recall, recall)": 0.07148365626551514,
                    "(litepyramid_recall, f1)": 0.05586427452396206
                }
            }
        },
        "bleurt": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.27598957193708096
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.16132519703275214
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.2330385330499019
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.060340399628791466
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.02998768175674908
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.043881550693140134
                }
            }
        },
        "bertscore-sentence": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, P)": 0.11266103562274864,
                    "(litepyramid_recall, R)": 0.23527810780006467,
                    "(litepyramid_recall, F)": 0.19317959626206033
                },
                "kendalltau": {
                    "(litepyramid_recall, P)": 0.07485475927541052,
                    "(litepyramid_recall, R)": 0.14989976583098513,
                    "(litepyramid_recall, F)": 0.12582607650701416
                },
                "spearmanr": {
                    "(litepyramid_recall, P)": 0.10660165311867588,
                    "(litepyramid_recall, R)": 0.21623148001353362,
                    "(litepyramid_recall, F)": 0.18054789713281627
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, P)": 0.018451597529333456,
                    "(litepyramid_recall, R)": 0.17396396291579957,
                    "(litepyramid_recall, F)": 0.16817103607428355
                },
                "kendalltau": {
                    "(litepyramid_recall, P)": 0.019848652671053846,
                    "(litepyramid_recall, R)": 0.11685916654209433,
                    "(litepyramid_recall, F)": 0.1142752792079305
                },
                "spearmanr": {
                    "(litepyramid_recall, P)": 0.02887930271611975,
                    "(litepyramid_recall, R)": 0.17139750531929557,
                    "(litepyramid_recall, F)": 0.1690092576047637
                }
            }
        }
    }
}