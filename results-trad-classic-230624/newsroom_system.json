{
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.4411226803,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.2592614353,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.3679498808,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.47029724,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.3438926891,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.464540201,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'precision')": 0.4479365669,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'recall')": 0.3613028648,
  "('spearmanr', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'f1')": 0.4528870642,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.4097195911,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.2660159175,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.3611229365,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.3553369581,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.3166988624,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.3957553549,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'precision')": 0.3689117535,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'recall')": 0.3753375275,
  "('spearmanr', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'f1')": 0.4151161286,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.3361469773,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.1400542879,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.2614198384,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.3739416114,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.1872489119,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.3152055796,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'precision')": 0.341236321,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'recall')": 0.2438157152,
  "('spearmanr', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'f1')": 0.3403741917,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.3428358413,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.1357493098,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.256229951,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.3591613576,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.2069196609,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.3113250919,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-bart-base', 'precision')": 0.3323786112,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-bart-base', 'recall')": 0.2197687043,
  "('spearmanr', 'FluencyRating', 'trad', 'bertscore-bart-base', 'f1')": 0.3337970121,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.4398035656,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.2691612828,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.3747746615,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.4485062305,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.3600525888,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.4336864723,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'precision')": 0.4207736153,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'recall')": 0.3743735035,
  "('pearsonr', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'f1')": 0.4247078939,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.3969540633,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.2503917947,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.3445840144,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.3810700213,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.2967533309,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.3686018346,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'precision')": 0.3540726583,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'recall')": 0.3557960337,
  "('pearsonr', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'f1')": 0.385697715,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.3158566859,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.1162108658,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.2241993711,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.3586148944,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.175406931,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.2885245976,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'precision')": 0.3125361868,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'recall')": 0.2123092044,
  "('pearsonr', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'f1')": 0.2917752867,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.2603619252,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.0863418482,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.1802204616,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.2930634027,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.1634979083,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.2491604148,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-bart-base', 'precision')": 0.2457843691,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-bart-base', 'recall')": 0.1582603297,
  "('pearsonr', 'FluencyRating', 'trad', 'bertscore-bart-base', 'f1')": 0.228455602,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.284429872,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.1779832801,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.2397909786,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.3210566563,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.2249113475,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.3050324382,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'precision')": 0.3015986771,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'recall')": 0.2432247396,
  "('kendalltau', 'InformativenessRating', 'trad', 'bertscore-bart-base', 'f1')": 0.287863633,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.2808333562,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.1824558872,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.2316446217,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.2488034826,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.2133418368,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.2705380397,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'precision')": 0.257954875,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'recall')": 0.2739698118,
  "('kendalltau', 'RelevanceRating', 'trad', 'bertscore-bart-base', 'f1')": 0.2831212043,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.2202053811,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.0886541145,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.1652970263,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.2488034826,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.11839614,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.2121979127,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'precision')": 0.2202053811,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'recall')": 0.1607213301,
  "('kendalltau', 'CoherenceRating', 'trad', 'bertscore-bart-base', 'f1')": 0.2270689255,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'precision')": 0.2230006376,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'recall')": 0.0914874411,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-roberta-base', 'f1')": 0.1646773939,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'precision')": 0.2458724979,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'recall')": 0.1383747546,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-deberta-base', 'f1')": 0.2058467424,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-bart-base', 'precision')": 0.2230006376,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-bart-base', 'recall')": 0.1475234987,
  "('kendalltau', 'FluencyRating', 'trad', 'bertscore-bart-base', 'f1')": 0.2127083005
}