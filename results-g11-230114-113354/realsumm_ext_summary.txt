corr_metric  aspect              approach  model                         score_name          
pearsonr     litepyramid_recall  trad      bertscore-deberta-large-mnli  precision              0.129
                                                                         recall                 0.253
                                                                         f1                     0.202
                                 new       bertscore-deberta-large-mnli  precision              0.021
                                                                         recall                 0.138
                                                                         f1                     0.106
                                 PreCalc   PreCalc                       rouge_1_f_score        0.187
                                                                         rouge_2_recall         0.236
                                                                         rouge_l_recall         0.251
                                                                         rouge_2_precision      0.163
                                                                         rouge_2_f_score        0.206
                                                                         rouge_1_precision      0.093
                                                                         rouge_1_recall         0.257
                                                                         rouge_l_precision      0.092
                                                                         rouge_l_f_score        0.188
                                                                         js-2                   0.195
                                                                         mover_score            0.205
                                                                         bert_recall_score      0.241
                                                                         bert_precision_score   0.088
                                                                         bert_f_score           0.182
kendalltau   litepyramid_recall  trad      bertscore-deberta-large-mnli  precision              0.110
                                                                         recall                 0.183
                                                                         f1                     0.153
                                 new       bertscore-deberta-large-mnli  precision              0.012
                                                                         recall                 0.089
                                                                         f1                     0.069
                                 PreCalc   PreCalc                       rouge_1_f_score        0.132
                                                                         rouge_2_recall         0.196
                                                                         rouge_l_recall         0.188
                                                                         rouge_2_precision      0.143
                                                                         rouge_2_f_score        0.167
                                                                         rouge_1_precision      0.073
                                                                         rouge_1_recall         0.192
                                                                         rouge_l_precision      0.072
                                                                         rouge_l_f_score        0.145
                                                                         js-2                   0.151
                                                                         mover_score            0.152
                                                                         bert_recall_score      0.162
                                                                         bert_precision_score   0.064
                                                                         bert_f_score           0.151
spearmanr    litepyramid_recall  trad      bertscore-deberta-large-mnli  precision              0.136
                                                                         recall                 0.214
                                                                         f1                     0.182
                                 new       bertscore-deberta-large-mnli  precision              0.016
                                                                         recall                 0.112
                                                                         f1                     0.087
                                 PreCalc   PreCalc                       rouge_1_f_score        0.153
                                                                         rouge_2_recall         0.221
                                                                         rouge_l_recall         0.214
                                                                         rouge_2_precision      0.169
                                                                         rouge_2_f_score        0.196
                                                                         rouge_1_precision      0.083
                                                                         rouge_1_recall         0.218
                                                                         rouge_l_precision      0.084
                                                                         rouge_l_f_score        0.165
                                                                         js-2                   0.180
                                                                         mover_score            0.190
                                                                         bert_recall_score      0.192
                                                                         bert_precision_score   0.077
                                                                         bert_f_score           0.178