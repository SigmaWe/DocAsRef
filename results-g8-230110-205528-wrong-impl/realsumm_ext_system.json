{
  "('pearsonr', 'litepyramid_recall', 'new', 'pagerank-cos-mpnet-entropy', 'score')": -0.083270425,
  "('pearsonr', 'litepyramid_recall', 'new', 'pagerank-cos-mpnet-sum', 'score')": -0.068231709,
  "('pearsonr', 'litepyramid_recall', 'new', 'pagerank-mnli-deberta-xlarge-entail_contradict-entropy', 'score')": -0.0158869716,
  "('pearsonr', 'litepyramid_recall', 'new', 'pagerank-mnli-deberta-xlarge-entail_contradict-sum', 'score')": -0.0439433055,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.3602821165,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.4593058289,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.4772754428,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.3779496024,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.4135786617,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.2633698812,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.4625354735,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.30351897,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.3885641196,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'js-2')": 0.4308285128,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'mover_score')": 0.3103351776,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_recall_score')": 0.4588322105,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_precision_score')": 0.3096964838,
  "('pearsonr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_f_score')": 0.4061485703,
  "('kendalltau', 'litepyramid_recall', 'new', 'pagerank-cos-mpnet-entropy', 'score')": -0.0999942676,
  "('kendalltau', 'litepyramid_recall', 'new', 'pagerank-cos-mpnet-sum', 'score')": -0.0601775457,
  "('kendalltau', 'litepyramid_recall', 'new', 'pagerank-mnli-deberta-xlarge-entail_contradict-entropy', 'score')": -0.0457305334,
  "('kendalltau', 'litepyramid_recall', 'new', 'pagerank-mnli-deberta-xlarge-entail_contradict-sum', 'score')": -0.0497774833,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.2391747367,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.3427766531,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.3140433091,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.2832864901,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.3075681893,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.1772564038,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.2990695946,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.2173212074,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.2662893007,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'js-2')": 0.3104010542,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'mover_score')": 0.2266291921,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_recall_score')": 0.3318498885,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_precision_score')": 0.2209634623,
  "('kendalltau', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_f_score')": 0.2958320347,
  "('spearmanr', 'litepyramid_recall', 'new', 'pagerank-cos-mpnet-entropy', 'score')": -0.1367001666,
  "('spearmanr', 'litepyramid_recall', 'new', 'pagerank-cos-mpnet-sum', 'score')": -0.0714564761,
  "('spearmanr', 'litepyramid_recall', 'new', 'pagerank-mnli-deberta-xlarge-entail_contradict-entropy', 'score')": -0.0656518832,
  "('spearmanr', 'litepyramid_recall', 'new', 'pagerank-mnli-deberta-xlarge-entail_contradict-sum', 'score')": -0.0703507337,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_f_score')": 0.3463586921,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_recall')": 0.479576805,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_recall')": 0.4560405448,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_precision')": 0.3954655806,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_2_f_score')": 0.4369030809,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_precision')": 0.2624575057,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_1_recall')": 0.4226024924,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_precision')": 0.3135507537,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'rouge_l_f_score')": 0.378860575,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'js-2')": 0.4354148115,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'mover_score')": 0.3243107013,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_recall_score')": 0.4405337381,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_precision_score')": 0.315309072,
  "('spearmanr', 'litepyramid_recall', 'PreCalc', 'PreCalc', 'bert_f_score')": 0.4033150013
}