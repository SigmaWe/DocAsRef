corr_metric  aspect              approach  model                         score_name          
pearsonr     litepyramid_recall  trad      bertscore-deberta-large-mnli  precision               0.275
                                                                         recall                  0.393
                                                                         f1                      0.339
                                 new       bertscore-deberta-large-mnli  precision               0.050
                                                                         recall                  0.121
                                                                         f1                      0.114
                                 PreCalc   PreCalc                       rouge_1_f_score         0.360
                                                                         rouge_2_recall          0.459
                                                                         rouge_l_recall          0.477
                                                                         rouge_2_precision       0.378
                                                                         rouge_2_f_score         0.414
                                                                         rouge_1_precision       0.263
                                                                         rouge_1_recall          0.463
                                                                         rouge_l_precision       0.304
                                                                         rouge_l_f_score         0.389
                                                                         js-2                    0.431
                                                                         mover_score             0.310
                                                                         bert_recall_score       0.459
                                                                         bert_precision_score    0.310
                                                                         bert_f_score            0.406
kendalltau   litepyramid_recall  trad      bertscore-deberta-large-mnli  precision               0.166
                                                                         recall                  0.248
                                                                         f1                      0.217
                                 new       bertscore-deberta-large-mnli  precision              -0.025
                                                                         recall                  0.116
                                                                         f1                      0.089
                                 PreCalc   PreCalc                       rouge_1_f_score         0.239
                                                                         rouge_2_recall          0.343
                                                                         rouge_l_recall          0.314
                                                                         rouge_2_precision       0.283
                                                                         rouge_2_f_score         0.308
                                                                         rouge_1_precision       0.177
                                                                         rouge_1_recall          0.299
                                                                         rouge_l_precision       0.217
                                                                         rouge_l_f_score         0.266
                                                                         js-2                    0.310
                                                                         mover_score             0.227
                                                                         bert_recall_score       0.332
                                                                         bert_precision_score    0.221
                                                                         bert_f_score            0.296
spearmanr    litepyramid_recall  trad      bertscore-deberta-large-mnli  precision               0.239
                                                                         recall                  0.354
                                                                         f1                      0.309
                                 new       bertscore-deberta-large-mnli  precision              -0.033
                                                                         recall                  0.161
                                                                         f1                      0.120
                                 PreCalc   PreCalc                       rouge_1_f_score         0.346
                                                                         rouge_2_recall          0.480
                                                                         rouge_l_recall          0.456
                                                                         rouge_2_precision       0.395
                                                                         rouge_2_f_score         0.437
                                                                         rouge_1_precision       0.262
                                                                         rouge_1_recall          0.423
                                                                         rouge_l_precision       0.314
                                                                         rouge_l_f_score         0.379
                                                                         js-2                    0.435
                                                                         mover_score             0.324
                                                                         bert_recall_score       0.441
                                                                         bert_precision_score    0.315
                                                                         bert_f_score            0.403