{
    "newsroom": {
        "rouge1": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.08137389912860474,
                    "(Informativeness, scores)": 0.1246247433589684,
                    "(Fluency, scores)": 0.05879014417530291,
                    "(Relevance, scores)": 0.14854632449137972
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.07564705664561523,
                    "(Informativeness, scores)": 0.1079115370346669,
                    "(Fluency, scores)": 0.05859000376507292,
                    "(Relevance, scores)": 0.11928495732936
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.102279252342022,
                    "(Informativeness, scores)": 0.14505252583914943,
                    "(Fluency, scores)": 0.07939192888688233,
                    "(Relevance, scores)": 0.15767208328648247
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.18042806312448775,
                    "(Informativeness, scores)": 0.3479617506230044,
                    "(Fluency, scores)": 0.13707078804654446,
                    "(Relevance, scores)": 0.27531589342282037
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.1800685030454464,
                    "(Informativeness, scores)": 0.3455235549108345,
                    "(Fluency, scores)": 0.13551656463852405,
                    "(Relevance, scores)": 0.25909125923689913
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.24219108713044332,
                    "(Informativeness, scores)": 0.45044963062537835,
                    "(Fluency, scores)": 0.1848421886632422,
                    "(Relevance, scores)": 0.3410161211340807
                }
            }
        },
        "rouge2": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.0378574605359331,
                    "(Informativeness, scores)": 0.09180874230869437,
                    "(Fluency, scores)": 0.027622653802722587,
                    "(Relevance, scores)": 0.108489605736017
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.07766164432733856,
                    "(Informativeness, scores)": 0.16181838257299938,
                    "(Fluency, scores)": 0.06655502919074092,
                    "(Relevance, scores)": 0.1492431526062508
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.09480048033116642,
                    "(Informativeness, scores)": 0.19671670452218826,
                    "(Fluency, scores)": 0.08187202021020341,
                    "(Relevance, scores)": 0.17954102814038866
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.20096227179966236,
                    "(Informativeness, scores)": 0.3655336738309423,
                    "(Fluency, scores)": 0.15763341924900903,
                    "(Relevance, scores)": 0.29420928346172726
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.2007244811553195,
                    "(Informativeness, scores)": 0.3644321922624369,
                    "(Fluency, scores)": 0.1553688614787737,
                    "(Relevance, scores)": 0.2782429817584937
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.26941673889254847,
                    "(Informativeness, scores)": 0.47187197421972776,
                    "(Fluency, scores)": 0.21117590986123866,
                    "(Relevance, scores)": 0.3622177402832377
                }
            }
        },
        "rougeL": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.05128061235817472,
                    "(Informativeness, scores)": 0.09810315477082669,
                    "(Fluency, scores)": 0.030839190011959942,
                    "(Relevance, scores)": 0.1247112639108498
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.055969435629232935,
                    "(Informativeness, scores)": 0.08720914720645004,
                    "(Fluency, scores)": 0.03977768128279695,
                    "(Relevance, scores)": 0.10288397823974575
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.07506431808763483,
                    "(Informativeness, scores)": 0.11731506648094661,
                    "(Fluency, scores)": 0.054060302025271116,
                    "(Relevance, scores)": 0.13619887083743
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.1944859744333834,
                    "(Informativeness, scores)": 0.3530565023740615,
                    "(Fluency, scores)": 0.14887140376885644,
                    "(Relevance, scores)": 0.282927825650849
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.19181806118814157,
                    "(Informativeness, scores)": 0.352506641948523,
                    "(Fluency, scores)": 0.147855886769678,
                    "(Relevance, scores)": 0.2669704868791073
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.25779000376329586,
                    "(Informativeness, scores)": 0.4592361177166287,
                    "(Fluency, scores)": 0.20096093693375527,
                    "(Relevance, scores)": 0.35122053248641644
                }
            }
        },
        "rougeLsum": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.05128061235817472,
                    "(Informativeness, scores)": 0.09810315477082669,
                    "(Fluency, scores)": 0.030839190011959942,
                    "(Relevance, scores)": 0.1247112639108498
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.055969435629232935,
                    "(Informativeness, scores)": 0.08720914720645004,
                    "(Fluency, scores)": 0.03977768128279695,
                    "(Relevance, scores)": 0.10288397823974575
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.07506431808763483,
                    "(Informativeness, scores)": 0.11731506648094661,
                    "(Fluency, scores)": 0.054060302025271116,
                    "(Relevance, scores)": 0.13619887083743
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.1944859744333834,
                    "(Informativeness, scores)": 0.3530565023740615,
                    "(Fluency, scores)": 0.14887140376885644,
                    "(Relevance, scores)": 0.282927825650849
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.19181806118814157,
                    "(Informativeness, scores)": 0.352506641948523,
                    "(Fluency, scores)": 0.147855886769678,
                    "(Relevance, scores)": 0.2669704868791073
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.25779000376329586,
                    "(Informativeness, scores)": 0.4592361177166287,
                    "(Fluency, scores)": 0.20096093693375527,
                    "(Relevance, scores)": 0.35122053248641644
                }
            }
        },
        "bertscore": {
            "trad": {
                "pearsonr": {
                    "(Coherence, precision)": 0.025892501789149407,
                    "(Coherence, recall)": 0.23722046345465578,
                    "(Coherence, f1)": 0.16469568478155816,
                    "(Informativeness, precision)": 0.02350316264092693,
                    "(Informativeness, recall)": 0.31777139113485775,
                    "(Informativeness, f1)": 0.21439769400685688,
                    "(Fluency, precision)": 0.026062288219015486,
                    "(Fluency, recall)": 0.19751990825008786,
                    "(Fluency, f1)": 0.1388123646960004,
                    "(Relevance, precision)": 0.06215380984028951,
                    "(Relevance, recall)": 0.30124344109626,
                    "(Relevance, f1)": 0.22579380641322128
                },
                "kendalltau": {
                    "(Coherence, precision)": 0.009753822344838315,
                    "(Coherence, recall)": 0.1515938976055398,
                    "(Coherence, f1)": 0.10523763966062899,
                    "(Informativeness, precision)": -0.0032626824937461055,
                    "(Informativeness, recall)": 0.21055356581702045,
                    "(Informativeness, f1)": 0.1363294674300363,
                    "(Fluency, precision)": 0.014619515477490944,
                    "(Fluency, recall)": 0.13020887109785,
                    "(Fluency, f1)": 0.08871334363258723,
                    "(Relevance, precision)": 0.04333089765548369,
                    "(Relevance, recall)": 0.19436940420523782,
                    "(Relevance, f1)": 0.14760663301611487
                },
                "spearmanr": {
                    "(Coherence, precision)": 0.01294876084651794,
                    "(Coherence, recall)": 0.20599280761644986,
                    "(Coherence, f1)": 0.1432364440791715,
                    "(Informativeness, precision)": -0.0024993828078641463,
                    "(Informativeness, recall)": 0.2816069996214018,
                    "(Informativeness, f1)": 0.18336352041235865,
                    "(Fluency, precision)": 0.019678186496804407,
                    "(Fluency, recall)": 0.176596889433331,
                    "(Fluency, f1)": 0.12080358088159503,
                    "(Relevance, precision)": 0.05829783480807423,
                    "(Relevance, recall)": 0.25802983812244146,
                    "(Relevance, f1)": 0.19682223135381496
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, precision)": 0.36972256392077235,
                    "(Coherence, recall)": 0.3262767109166328,
                    "(Coherence, f1)": 0.37694173203246195,
                    "(Informativeness, precision)": 0.4725479432167582,
                    "(Informativeness, recall)": 0.4696785407236027,
                    "(Informativeness, f1)": 0.5084202670967373,
                    "(Fluency, precision)": 0.31920906227584755,
                    "(Fluency, recall)": 0.27018770476313025,
                    "(Fluency, f1)": 0.31929782207911,
                    "(Relevance, precision)": 0.4292615548803437,
                    "(Relevance, recall)": 0.40253471247849504,
                    "(Relevance, f1)": 0.4498848450922489
                },
                "kendalltau": {
                    "(Coherence, precision)": 0.2580071776649828,
                    "(Coherence, recall)": 0.23511959572286334,
                    "(Coherence, f1)": 0.25790309063240113,
                    "(Informativeness, precision)": 0.330907628305214,
                    "(Informativeness, recall)": 0.35240053088659856,
                    "(Informativeness, f1)": 0.36311762830870115,
                    "(Fluency, precision)": 0.2203248325021264,
                    "(Fluency, recall)": 0.18133088088435012,
                    "(Fluency, f1)": 0.2102382674088267,
                    "(Relevance, precision)": 0.27648241172432747,
                    "(Relevance, recall)": 0.2723160074499801,
                    "(Relevance, f1)": 0.2890168088199185
                },
                "spearmanr": {
                    "(Coherence, precision)": 0.3405376002340814,
                    "(Coherence, recall)": 0.31217058619269517,
                    "(Coherence, f1)": 0.34087637314002006,
                    "(Informativeness, precision)": 0.4304723692737013,
                    "(Informativeness, recall)": 0.4586768231384467,
                    "(Informativeness, f1)": 0.4711100688613698,
                    "(Fluency, precision)": 0.2910435585182629,
                    "(Fluency, recall)": 0.24356445591096249,
                    "(Fluency, f1)": 0.2799229609896067,
                    "(Relevance, precision)": 0.3603590564034967,
                    "(Relevance, recall)": 0.35634306507509633,
                    "(Relevance, f1)": 0.3762665735248818
                }
            }
        },
        "bleurt": {
            "trad": {
                "pearsonr": {
                    "(Coherence, scores)": 0.14322046019870993,
                    "(Informativeness, scores)": 0.24445229934562912,
                    "(Fluency, scores)": 0.11064269287092389,
                    "(Relevance, scores)": 0.23258492964505284
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.09355544879890494,
                    "(Informativeness, scores)": 0.18400032217429957,
                    "(Fluency, scores)": 0.07251434063035915,
                    "(Relevance, scores)": 0.14494307677707538
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.12676048564162753,
                    "(Informativeness, scores)": 0.24446582890578955,
                    "(Fluency, scores)": 0.09767340599904382,
                    "(Relevance, scores)": 0.19465601567860064
                }
            },
            "new": {
                "pearsonr": {
                    "(Coherence, scores)": 0.2998783333885462,
                    "(Informativeness, scores)": 0.4130435849680887,
                    "(Fluency, scores)": 0.2583858349704224,
                    "(Relevance, scores)": 0.3446757569445662
                },
                "kendalltau": {
                    "(Coherence, scores)": 0.20241891965346318,
                    "(Informativeness, scores)": 0.3033825057286443,
                    "(Fluency, scores)": 0.17148447210279566,
                    "(Relevance, scores)": 0.24313651741598655
                },
                "spearmanr": {
                    "(Coherence, scores)": 0.2699867231848094,
                    "(Informativeness, scores)": 0.39923481164882607,
                    "(Fluency, scores)": 0.22907713345573394,
                    "(Relevance, scores)": 0.3215046976559067
                }
            }
        }
    },
    "realsumm_abs": {
        "rouge1": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5840501663551281
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.41054106736403634
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5728265389879345
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.3233123444275029
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.21543617665062453
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.31698043204022797
                }
            }
        },
        "rouge2": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5655386668052393
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.4129394700887854
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5758401967870274
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.32411722841106394
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.2173068213130148
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.32019622910470497
                }
            }
        },
        "rougeL": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5128340976719938
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.35970070962517414
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5103572079605415
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.32676399139344814
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.2174161106949151
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.3200441891567805
                }
            }
        },
        "rougeLsum": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5128340976719938
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.35970070962517414
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5103572079605415
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.32676399139344814
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.2174161106949151
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.3200441891567805
                }
            }
        },
        "bertscore": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, precision)": 0.31580603601666934,
                    "(litepyramid_recall, recall)": 0.5595097479766471,
                    "(litepyramid_recall, f1)": 0.470300093738961
                },
                "kendalltau": {
                    "(litepyramid_recall, precision)": 0.20312795913327433,
                    "(litepyramid_recall, recall)": 0.3793688677839019,
                    "(litepyramid_recall, f1)": 0.31204834461676484
                },
                "spearmanr": {
                    "(litepyramid_recall, precision)": 0.2977959681693379,
                    "(litepyramid_recall, recall)": 0.5347068367281448,
                    "(litepyramid_recall, f1)": 0.4478589587693725
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, precision)": 0.036766861042003676,
                    "(litepyramid_recall, recall)": 0.3248452746491779,
                    "(litepyramid_recall, f1)": 0.1914281417979327
                },
                "kendalltau": {
                    "(litepyramid_recall, precision)": 0.030790046802229507,
                    "(litepyramid_recall, recall)": 0.21789433806062222,
                    "(litepyramid_recall, f1)": 0.12937211185668837
                },
                "spearmanr": {
                    "(litepyramid_recall, precision)": 0.04570936460577797,
                    "(litepyramid_recall, recall)": 0.32074181821543357,
                    "(litepyramid_recall, f1)": 0.1928604827621306
                }
            }
        },
        "bleurt": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.5639529039182334
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.38726835325371395
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.5448529525837188
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.23286929878314155
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.15180020999940166
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.22489590287772943
                }
            }
        }
    },
    "realsumm_ext": {
        "rouge1": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.2547127415815572
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.14861665986848718
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.20988246942755948
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.17056769992946544
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.11668324576907085
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.1707065957005945
                }
            }
        },
        "rouge2": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.2971352930625117
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.19116419778764435
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.2712405237874062
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.16979206605718555
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.119155874680575
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.1740230088329624
                }
            }
        },
        "rougeL": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.24168161174441327
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.15966207551799702
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.2316855126892376
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.17064807216820463
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.11848948672705939
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.17271776887656132
                }
            }
        },
        "rougeLsum": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.24168161174441327
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.15966207551799702
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.2316855126892376
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.17064807216820463
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.11848948672705939
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.17271776887656132
                }
            }
        },
        "bertscore": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, precision)": 0.14313472913055458,
                    "(litepyramid_recall, recall)": 0.28390695414397715,
                    "(litepyramid_recall, f1)": 0.22501962492828387
                },
                "kendalltau": {
                    "(litepyramid_recall, precision)": 0.08521112037045707,
                    "(litepyramid_recall, recall)": 0.1732579957218556,
                    "(litepyramid_recall, f1)": 0.13745431050772053
                },
                "spearmanr": {
                    "(litepyramid_recall, precision)": 0.12283493978756785,
                    "(litepyramid_recall, recall)": 0.24956016413997495,
                    "(litepyramid_recall, f1)": 0.19778539673014459
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, precision)": 0.03531317053455697,
                    "(litepyramid_recall, recall)": 0.09073690022165626,
                    "(litepyramid_recall, f1)": 0.06718809172240796
                },
                "kendalltau": {
                    "(litepyramid_recall, precision)": 0.02440550827330555,
                    "(litepyramid_recall, recall)": 0.049086580621041764,
                    "(litepyramid_recall, f1)": 0.037999180258573566
                },
                "spearmanr": {
                    "(litepyramid_recall, precision)": 0.03505721245130046,
                    "(litepyramid_recall, recall)": 0.07147978589596034,
                    "(litepyramid_recall, f1)": 0.05586095472205715
                }
            }
        },
        "bleurt": {
            "trad": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.27598918859939253
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.16133375638247577
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.23304264278372805
                }
            },
            "new": {
                "pearsonr": {
                    "(litepyramid_recall, scores)": 0.060340096339920005
                },
                "kendalltau": {
                    "(litepyramid_recall, scores)": 0.0300019473396218
                },
                "spearmanr": {
                    "(litepyramid_recall, scores)": 0.043896416724389244
                }
            }
        }
    }
}